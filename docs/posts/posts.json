[
  {
    "path": "posts/2021-01-13-data-clinics-in-nottinghamshire-healthcare/",
    "title": "Data clinics in Nottinghamshire Healthcare",
    "description": "We have been working with teams to help them with their data problems. This post describes some of the clinics and what has come about as a result of this work.",
    "author": [
      {
        "name": "Lori Edwards Suárez",
        "url": {
          "https://twitter.com/Lori_E_S_": {}
        }
      }
    ],
    "date": "2021-01-13",
    "categories": [],
    "contents": "\nOur team recently piloted data clinics within the Trust in order to:\nImprove data quality and completeness\nImprove the means by which staff collect and record the essential information, making it more efficient and freeing them up to spend more time with their patients.\nThis was achieved by going “back to basics” with the people who collect and input data, the key principles are ensuring they know why they are collecting the data, making sure the data collection system works well for the teams and that the data can be used by both the data collectors and analysts. A variety of avenues were considered, such as reducing excess data collection and reducing duplication which make data gathering more laborious and tedious for clinicians.\nWhen data collection is difficult for clinicians it often results in the data not being filled properly, correcting this increases the accuracy and completeness of the dataset. Structuring clinical records and decreasing their reliaance on free text input is also beneficial for data analysis but is also often faster and easier for clinical staff. The clinics are a collaborative venture with the clinical team and others such as analysts and system admin, the type of staff varies depending on the needs of each teams. My role was to facilitate the conversations using skills learnt from working closely with the clinical teams to learn to “translate” between clinical language and data/IT language. Subtle differences in expression between the two groups often lead to misunderstandings which could stifle progress (more examples). The key element was that the problem was generated by the team themselves. This ensures that the clinic is focused on solving their difficulties which should help them to improve their own systems rather than forcing a change on them.\nAs a test run we had two teams go through the process:\nA forensic mental health team which wanted to move away from using Excel to collect their data\nA community mental health team which wanted to collect some extra information to better understand the impact of their team without adding too much to their workload\nThe forensic team was a new service which had a lot of data requested of them and they wished to improve their data collection and assess its quality. The Team Leader had used team-specific forms in RiO (the clinical database which they use) previously and was interested in seeing if it was possible here. However, they were having a tough time explaining to the managers who were not familiar with such a system how to approve it and get it built into the system. The spreadsheet was found to have a lot of duplication and data being requested that was not necessarily attainable by the team. We looked together at what the purpose was and changed some of the data from free text to a more structured pick list from the valid values for that piece of data. We also had to explain to the managers that this change was not going to affect their reporting adversely. The patient record system was able to provide the team with what they needed and to automate some aspects to reduce workload for clinicians. Some outcomes measures already existed but others were not yet available on the system, an Excel sheet was made to collect them (an improvement over a folder in the corner of the room) with a reduction in demand for clinicians with simple automation of score summations. The team are thrilled that they can collect the data necessary for reporting and understanding their service in a more intuitive way, project managers are content they are getting the same information and more data is readily available for service improvement. Reports are being built which give the clinicians easy access to data which allows them to engage better and feel ownership of the data.\nThe community mental health team wanted to collect some more information to improve their ability to understand their outcomes. They needed to be able to distinguish between the cohorts of patients that were being referred. This ended up having a simple solution that had not been known to the clinical team – adding in more specific referral reasons. The patient cohort was clear and defined and could be determined at referral. They wanted some more information on one of the cohorts to understand the group further and to see how specific patients within the group progressed. To gather this data, a short form on the electronic patient record was created which takes one minute to fill in but adds a wealth of information. The team also got to play with the form before it went live to gain familiarity and to help them feel ownership of it. They also wanted to be able to predict when referrals may come in. As we got to know the pathways that brought patients into the service, we learned that we had information about patientes in the previous stage of the pathway. So, we managed to collect some information to understand the time between the previous stage and the referral. This means we can see when there is an uptick in people passing through the previous stage and predict a spike in referrals for the team to prepare for.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-13T17:00:13+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-14-classification-of-patient-feedback/",
    "title": "Classification of patient feedback",
    "description": "An NHSE funded project to devise an application to automatically tag the content of patient feedback",
    "author": [
      {
        "name": "Andreas Soteriades",
        "url": {}
      }
    ],
    "date": "2020-11-14",
    "categories": [],
    "contents": "\nConsider the following problem. A NHS trust is devoted to improving their services to provide patients with the best possible experience. The trust sets up a Patient Feedback system in order to identify key areas of improvement. Specialized trust staff (the “coders”) read the feedback and decide what it is about. For example, if the feedback is “The doctor carefully listened to me and clearly explained me the possible solutions”, then the coders can safely conclude that the feedback is about communication.\nBut what happens when thousands and thousands of patient feedback records are populating the trust’s database every few days? Can the coders keep up with tagging such a high volume of records? After all, unless they read all of it, they cannot tag it!\nWe need to find a clever way to get some weight off the coders’ shoulders!\nHere in Nottinghamshire Healthcare NHS Foundation Trust, we (the Data Science team) have opted for a Machine Learning approach to help coders tag the incoming patient feedback. In particular, we are developing Text Classification algorithms that “read” the feedback and decide what it is about.\nFirst things first: what are Machine Learning and Text Classification?\nMachine Learning is a wider concept, but here we will talk about the so-called supervised Machine Learning. Say a child is playing with a hole cube:\n\nBy trying to pass different shapes through different holes, the child follows a process of “training” or “learning”, through which they learn to identify the right shape for each hole. Once they have been “trained”, they can easily predict what shape is the right one for a specific hole, on this or any other hole cube.\nThe process that the child has just followed is very similar to Machine Learning: see the child as an algorithm, the shapes as a dataset, and the holes as tags and you have a supervised Machine Learning problem. In other words, in supervised Machine Learning the algorithm “learns from” or “is trained on” the dataset, and thus becomes able to predict what tag corresponds to each record.\nSo when we have patient feedback data that have already been tagged by our coders, we can train an algorithm to assign the most appropriate tag to each feedback record, based on the content of the feedback text. As fresh, untagged feedback populates the trust’s database, the algorithm is then able to predict the most appropriate tag for it. In other words, the algorithm learns to automatically classify the text according its content, which is what Text Classification is about: a form of supervised Machine Learning that is about predicting the appropriate tag for the given text.\nHow can Text Classification improve NHS services?\nIncrease tagging speed. As mentioned earlier, the idea is to have the algorithm automatically tag feedback that the coders simply do not have time to read and tag themselves. To begin with, it will make the process of tagging much more efficient.\nNarrow down searches for NHS staff. If a member of staff (e.g. manager, doctor, nurse) wishes to focus on improve patient experience that has to do with, e.g. communication, they will want to read some or all of the incoming feedback about it. The algorithm will crunch the incoming feedback, decide which records are about communication, and feed them back to the member of staff.\nAre there any cons?\nAlgorithms make errors. For example, an algorithm may incorrectly classify feedback about smoking as being about communication. This is to be expected as no algorithm can ever be 100% accurate. What is key then is to make the algorithm as accurate as possible for the task at hand. This is an area where we focus on on a daily basis.\nDespite some inaccuracies, Machine Learning will still offer the great advantage of narrowing down NHS staff searches almost exclusively to the feedback of interest. If a manager has 100 feedback records of which only 20 are potentially relevant, and the algorithm predicts that 30 are potentially relevant (because it will make a few mistakes), this would still be a 70% reduction in the number of feedback records to be read by the manager!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-13T12:16:39+00:00",
    "input_file": {}
  }
]
