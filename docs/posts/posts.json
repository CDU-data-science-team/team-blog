[
  {
    "path": "posts/2021-01-20-a-new-github-release-and-future-projects/",
    "title": "A new GitHub release and future projects",
    "description": "We have a new project out and would like to tell you about some more of our future work.",
    "author": [
      {
        "name": "Chris Beeley",
        "url": {}
      }
    ],
    "date": "2021-01-20",
    "categories": [],
    "contents": "\nIf you‚Äôve read the about section of this blog then you‚Äôll know that our team believes in (and practises!) open source data science. We strive to put as much code and (sometimes synthetic) data out as possible, with an open source licence (MIT, usually), and where we can we try to make our code reasonably easy to re-use (although this is not always simple). We have just pushed out a prototype version of an application and this seemed like a timely moment to talk about the application, and what else we have coming up on the open source side of things. It‚Äôs worth saying that some of our team members work really, really hard doing lots of stuff that is very difficult to share so although you might not see as much of them on the GitHub they‚Äôre doing sterling work for the Trust and the team is dependent on their expertise for all of our work, whether it‚Äôs open source or not.\nText mining application\nWe already have a blog post about this work and we have come to the point where we have produced a release version (0.1.0) for the dashboard which summarises the acccuracy of the models and helps to show the kinds of decisions that it‚Äôs making. Please read the blog post for details of this work but our ambition in brief is to produce a text mining algorithm for patient experience that can be used in any NHS organisation in the country. The actual algorithm work (which is in Python mainly) has not yet stabilised to a release version just yet but is available on GitHub.\nWe will be shipping another dashboard that helps trusts to visualise their feedback as part of the project. We‚Äôre currently working on that but we‚Äôre not quite ready to share it yet, keep an eye on our Twitter and blog for more details. We have a lot more to come in the way of working with staff and patient experience data, too, it‚Äôs not just this work, so please feel free to follow along with the code once it‚Äôs all open and maybe even send us a pull request üòâ.\nForecasting of patient numbers\nWe‚Äôre also involved in a Health Foundation funded project which looks at predicting numbers of certain types of patients in the hospital. It takes the form of a dashboard which can predict the numbers of patients likely to fall into particular categories in the next 1-10 days based on previous data of this kind. The model has complex seasonality (although currently it achieves better results if you constrain it to results since April because of COVID) and a TBATS model produced the best results. The code is MIT open source and could be easily adapted to predict lots of different univariate series. There are lots of other people involved in this project and written materials from them are forthcoming, I will add them to this blog post once they are available. Our role was just to help with the forecasting and write the dashboard, lots of other work has gone into it.\nForecasting pharmacy dispensing\nThis is another Health Foundation funded forecasting project which attempts to predict the amount of many different medications which will be dispensed from a pharmacy in order to better manage stock levels. Again the code for our bit is open source MIT, although it is very early days for this project so there will be much more to come. There is much more to this project than just the code, and I will update this blog post with more details once more of the outputs are ready.\nA Shiny interface to EndomineR\nThis work relates to another Health Foundation funded project but it was funded by NHS-R. EndomineR is a clinical text mining system which works with endoscopic reports and helps to collate and analyse data from free text reports automatically. This work replicates an existing Shiny interface but uses the {golem} package to rewrite the code within modules and to make the application run as an R package. This will make the code easier to maintain, update, and generalise to other clinical settings. This project is currently in active development but it should be ready for a first release in February some time, the code again available open source on GitHub.\n{golem}, gitflow, and production data science\nWe are all still learning but we are trying to use good methods to make sure that our code is robust and easy to deploy, and to help us collaborate with each other. To this end we:\nUse the {golem} package for a lot of our Shiny work, and modularise our Shiny code\nUse RStudio Connect (I have written some stuff about this on my own blog)\nUse gitflow\nHave regular (two weekly) code review sessions\nI‚Äôm really interested in understanding how to get better at working together in the open and tools to help code easy to deploy and generalise. If you‚Äôre interested in that too, especially if you work in the NHS (some of the hurdles are the same size and height everywhere in the NHS üòÜ) then please get in touch.\nWe have lots of stuff planned including better analysis of HoNOS data, more to come on staff and patient experience, methods for summarising clinical outcomes and health inequalities, and other stuff from team members where I‚Äôm not quite sure how close they are to launch. Please watch out for regular updates if you would like to see more stuff from us, on our Twitter and on this blog.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-22T10:01:40+00:00",
    "input_file": "a-new-github-release-and-future-projects.utf8.md"
  },
  {
    "path": "posts/2021-01-13-data-clinics-in-nottinghamshire-healthcare/",
    "title": "Data clinics in Nottinghamshire Healthcare",
    "description": "We have been working with teams to help them with their data problems. This post describes some of the clinics and what has come about as a result of this work.",
    "author": [
      {
        "name": "Lori Edwards Su√°rez",
        "url": {
          "https://twitter.com/Lori_E_S_": {}
        }
      }
    ],
    "date": "2021-01-13",
    "categories": [],
    "contents": "\nOur team recently piloted data clinics within the Trust in order to:\nImprove data quality and completeness\nImprove the means by which staff collect and record the essential information, making it more efficient and freeing them up to spend more time with their patients.\nThis was achieved by going ‚Äúback to basics‚Äù with the people who collect and input data, the key principles are ensuring they know why they are collecting the data, making sure the data collection system works well for the teams and that the data can be used by both the data collectors and analysts. A variety of avenues were considered, such as reducing excess data collection and reducing duplication which make data gathering more laborious and tedious for clinicians.\nWhen data collection is difficult for clinicians it often results in the data not being filled properly, correcting this increases the accuracy and completeness of the dataset. Structuring clinical records and decreasing their reliaance on free text input is also beneficial for data analysis but is also often faster and easier for clinical staff. The clinics are a collaborative venture with the clinical team and others such as analysts and system admin, the type of staff varies depending on the needs of each teams. My role was to facilitate the conversations using skills learnt from working closely with the clinical teams to learn to ‚Äútranslate‚Äù between clinical language and data/IT language. Subtle differences in expression between the two groups often lead to misunderstandings which could stifle progress (more examples). The key element was that the problem was generated by the team themselves. This ensures that the clinic is focused on solving their difficulties which should help them to improve their own systems rather than forcing a change on them.\nAs a test run we had two teams go through the process:\nA forensic mental health team which wanted to move away from using Excel to collect their data\nA community mental health team which wanted to collect some extra information to better understand the impact of their team without adding too much to their workload\nThe forensic team was a new service which had a lot of data requested of them and they wished to improve their data collection and assess its quality. The Team Leader had used team-specific forms in RiO (the clinical database which they use) previously and was interested in seeing if it was possible here. However, they were having a tough time explaining to the managers who were not familiar with such a system how to approve it and get it built into the system. The spreadsheet was found to have a lot of duplication and data being requested that was not necessarily attainable by the team. We looked together at what the purpose was and changed some of the data from free text to a more structured pick list from the valid values for that piece of data. We also had to explain to the managers that this change was not going to affect their reporting adversely. The patient record system was able to provide the team with what they needed and to automate some aspects to reduce workload for clinicians. Some outcomes measures already existed but others were not yet available on the system, an Excel sheet was made to collect them (an improvement over a folder in the corner of the room) with a reduction in demand for clinicians with simple automation of score summations. The team are thrilled that they can collect the data necessary for reporting and understanding their service in a more intuitive way, project managers are content they are getting the same information and more data is readily available for service improvement. Reports are being built which give the clinicians easy access to data which allows them to engage better and feel ownership of the data.\nThe community mental health team wanted to collect some more information to improve their ability to understand their outcomes. They needed to be able to distinguish between the cohorts of patients that were being referred. This ended up having a simple solution that had not been known to the clinical team ‚Äì adding in more specific referral reasons. The patient cohort was clear and defined and could be determined at referral. They wanted some more information on one of the cohorts to understand the group further and to see how specific patients within the group progressed. To gather this data, a short form on the electronic patient record was created which takes one minute to fill in but adds a wealth of information. The team also got to play with the form before it went live to gain familiarity and to help them feel ownership of it. They also wanted to be able to predict when referrals may come in. As we got to know the pathways that brought patients into the service, we learned that we had information about patientes in the previous stage of the pathway. So, we managed to collect some information to understand the time between the previous stage and the referral. This means we can see when there is an uptick in people passing through the previous stage and predict a spike in referrals for the team to prepare for.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-13T17:00:13+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-14-classification-of-patient-feedback/",
    "title": "Classification of patient feedback",
    "description": "An NHSE funded project to devise an application to automatically tag the content of patient feedback",
    "author": [
      {
        "name": "Andreas Soteriades",
        "url": {}
      }
    ],
    "date": "2020-11-14",
    "categories": [],
    "contents": "\nConsider the following problem. A NHS trust is devoted to improving their services to provide patients with the best possible experience. The trust sets up a Patient Feedback system in order to identify key areas of improvement. Specialized trust staff (the ‚Äúcoders‚Äù) read the feedback and decide what it is about. For example, if the feedback is ‚ÄúThe doctor carefully listened to me and clearly explained me the possible solutions‚Äù, then the coders can safely conclude that the feedback is about communication.\nBut what happens when thousands and thousands of patient feedback records are populating the trust‚Äôs database every few days? Can the coders keep up with tagging such a high volume of records? After all, unless they read all of it, they cannot tag it!\nWe need to find a clever way to get some weight off the coders‚Äô shoulders!\nHere in Nottinghamshire Healthcare NHS Foundation Trust, we (the Data Science team) have opted for a Machine Learning approach to help coders tag the incoming patient feedback. In particular, we are developing Text Classification algorithms that ‚Äúread‚Äù the feedback and decide what it is about.\nFirst things first: what are Machine Learning and Text Classification?\nMachine Learning is a wider concept, but here we will talk about the so-called supervised Machine Learning. Say a child is playing with a hole cube:\n\nBy trying to pass different shapes through different holes, the child follows a process of ‚Äútraining‚Äù or ‚Äúlearning‚Äù, through which they learn to identify the right shape for each hole. Once they have been ‚Äútrained‚Äù, they can easily predict what shape is the right one for a specific hole, on this or any other hole cube.\nThe process that the child has just followed is very similar to Machine Learning: see the child as an algorithm, the shapes as a dataset, and the holes as tags and you have a supervised Machine Learning problem. In other words, in supervised Machine Learning the algorithm ‚Äúlearns from‚Äù or ‚Äúis trained on‚Äù the dataset, and thus becomes able to predict what tag corresponds to each record.\nSo when we have patient feedback data that have already been tagged by our coders, we can train an algorithm to assign the most appropriate tag to each feedback record, based on the content of the feedback text. As fresh, untagged feedback populates the trust‚Äôs database, the algorithm is then able to predict the most appropriate tag for it. In other words, the algorithm learns to automatically classify the text according its content, which is what Text Classification is about: a form of supervised Machine Learning that is about predicting the appropriate tag for the given text.\nHow can Text Classification improve NHS services?\nIncrease tagging speed. As mentioned earlier, the idea is to have the algorithm automatically tag feedback that the coders simply do not have time to read and tag themselves. To begin with, it will make the process of tagging much more efficient.\nNarrow down searches for NHS staff. If a member of staff (e.g.¬†manager, doctor, nurse) wishes to focus on improve patient experience that has to do with, e.g.¬†communication, they will want to read some or all of the incoming feedback about it. The algorithm will crunch the incoming feedback, decide which records are about communication, and feed them back to the member of staff.\nAre there any cons?\nAlgorithms make errors. For example, an algorithm may incorrectly classify feedback about smoking as being about communication. This is to be expected as no algorithm can ever be 100% accurate. What is key then is to make the algorithm as accurate as possible for the task at hand. This is an area where we focus on on a daily basis.\nDespite some inaccuracies, Machine Learning will still offer the great advantage of narrowing down NHS staff searches almost exclusively to the feedback of interest. If a manager has 100 feedback records of which only 20 are potentially relevant, and the algorithm predicts that 30 are potentially relevant (because it will make a few mistakes), this would still be a 70% reduction in the number of feedback records to be read by the manager!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-13T12:16:39+00:00",
    "input_file": {}
  }
]
